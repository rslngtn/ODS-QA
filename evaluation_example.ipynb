{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text # Not used directly but needed to import TF ops.\n",
    "\n",
    "from modules.evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hub.KerasLayer(\"models/USEm_large3\")\n",
    "df = pd.read_parquet('data/qa_clean.parquet')\n",
    "graph = pd.read_parquet('data/qa_sim.parquet').loc[:, ['q_id', 'ans_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df['question'].unique()\n",
    "answers = df['answer'].to_numpy()\n",
    "similarity = []\n",
    "for st in graph['ans_ids'].to_numpy():\n",
    "    el = eval(st)\n",
    "    if isinstance(el, int):\n",
    "        similarity.append([el])\n",
    "    else:\n",
    "        similarity.append(list(el))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем MAP@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 100%|██████████| 328/328 [26:06<00:00,  4.78s/it]\n",
      "Calculating embeddings: 100%|██████████| 771/771 [37:17<00:00,  2.90s/it]\n",
      "Searching for top k texts for all inputs: 100%|██████████| 21018/21018 [14:46<00:00, 23.70it/s]\n"
     ]
    }
   ],
   "source": [
    "map10 = evaluate(model, questions, answers, similarity, model_type='use', batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06969540386306033\n"
     ]
    }
   ],
   "source": [
    "print(map10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор кандидатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/qq_sim.parquet')\n",
    "questions = df['question'].unique()\n",
    "model = hub.KerasLayer(\"models/USEm_large3\")\n",
    "df['checked'] = False\n",
    "df['scores'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Calculating embeddings: 100%|██████████| 80/80 [06:34<00:00,  4.93s/it]\nCalculating embeddings: 100%|██████████| 80/80 [06:08<00:00,  4.61s/it]\nSearching for top k texts for all inputs: 100%|██████████| 5161/5161 [00:25<00:00, 203.49it/s]\n"
    }
   ],
   "source": [
    "from modules.evaluation import calculate_embeddings, Index\n",
    "from tqdm import tqdm\n",
    "\n",
    "embs = calculate_embeddings(model, questions, dims=512, model_type='use')\n",
    "search_index = Index(model, questions, 512, model_type='use')\n",
    "candidates = []\n",
    "for i, _ in tqdm(enumerate(questions), desc='Searching for top k texts for all inputs', total=len(questions)):\n",
    "    texts, _ = search_index.search(embs[i].reshape((1, -1)), k=11) #search wants 2 dims\n",
    "    candidates.append(texts[1:])\n",
    "\n",
    "df['candidates'] = candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, elasticsearch, json\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "# index and document type constants\n",
    "INDEX_NAME = \"documents\"\n",
    "TYPE = \"document\"\n",
    "\n",
    "# get a client\n",
    "es = Elasticsearch()\n",
    "\n",
    "# create an index, ignore if it exists already\n",
    "es.indices.create(index='documents', ignore=400)\n",
    "\n",
    "# json-ize the lines in the file\n",
    "def make_documents(f):\n",
    "    for l in f:\n",
    "        doc = {\n",
    "                '_op_type': 'create',\n",
    "                '_index': INDEX_NAME,\n",
    "                '_type': TYPE,\n",
    "                '_source': {'text': l.strip() }\n",
    "        }\n",
    "        yield( doc )            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Ok. I've got an index of 2445 documents. Let's do some searches...\n"
    }
   ],
   "source": [
    "# put documents in index in bulk\n",
    "bulk(es, make_documents(questions))\n",
    "\n",
    "# count the matches\n",
    "count = es.count(index=INDEX_NAME, doc_type=TYPE, body={ \"query\": {\"match_all\" : { }}})\n",
    "\n",
    "# now we can do searches.\n",
    "print(\"Ok. I've got an index of {0} documents. Let's do some searches...\".format(count['count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Elastic search по всем вопросам: 100%|██████████| 5161/5161 [00:23<00:00, 223.94it/s]\n"
    }
   ],
   "source": [
    "candidates = []\n",
    "for i, row in tqdm(df.iterrows(), desc='Elastic search по всем вопросам', total=len(df)):\n",
    "    local_cands = list(row['candidates'])\n",
    "    results = es.search(index=INDEX_NAME, doc_type=TYPE, body={\"query\": {\"match\": {\"text\": row['question']}}})\n",
    "    for res in results['hits']['hits'][1:6]:\n",
    "        local_cands.append(res['_source']['text'])\n",
    "\n",
    "    candidates.append(local_cands)\n",
    "\n",
    "df['candidates'] = candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'А кто-нибудь пробовал работать с корпусом изданных книг? Грубо говоря скачать флибусту и дальше на основе этих данных делать модели / аналитику.\\nМне интересен опыт работы с данными и какие задачи на них решались и кто сейчас занимается этим.\\nНапример, насколько реально (и сложно) оценить уровень языка, грамотность, ожидаемую популярность книги, издаваемость (форматность) книги и т.п.'"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df.loc[1, 'candidates'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                            question  \\\n0  Народ, кто знает, есть ли в GO библиотека для ...   \n1  Всем привет, нуждаюсь в помощи по составлению ...   \n2  и еще вопрос, нет ли веяний, что этот проект п...   \n3  Кто-нибудь здесь проходил\\n<http://coursera.or...   \n4  Кто-нибудь знает готовые реализации для обнару...   \n\n  similiar_questions_ids_in_clean_df question_ids_in_clean_df  checked  \\\n0                               None                        0    False   \n1                               None               1, 2, 3, 4    False   \n2                               None                     5, 6    False   \n3                               None                        7    False   \n4                               None                       66    False   \n\n                                          candidates  scores  \n0  [Ребята, привет!\\nНа днях коллега из академии ...     NaN  \n1  [Прошел ассессмент на Senior Systems Engineer ...     NaN  \n2  [Кто-нибудь знает, есть ли что-нибудь похожее ...     NaN  \n3  [<https://www.coursera.org/learn/reinforcement...     NaN  \n4  [Что можно почитать на тему отслеживание анома...     NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>similiar_questions_ids_in_clean_df</th>\n      <th>question_ids_in_clean_df</th>\n      <th>checked</th>\n      <th>candidates</th>\n      <th>scores</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Народ, кто знает, есть ли в GO библиотека для ...</td>\n      <td>None</td>\n      <td>0</td>\n      <td>False</td>\n      <td>[Ребята, привет!\\nНа днях коллега из академии ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Всем привет, нуждаюсь в помощи по составлению ...</td>\n      <td>None</td>\n      <td>1, 2, 3, 4</td>\n      <td>False</td>\n      <td>[Прошел ассессмент на Senior Systems Engineer ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>и еще вопрос, нет ли веяний, что этот проект п...</td>\n      <td>None</td>\n      <td>5, 6</td>\n      <td>False</td>\n      <td>[Кто-нибудь знает, есть ли что-нибудь похожее ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Кто-нибудь здесь проходил\\n&lt;http://coursera.or...</td>\n      <td>None</td>\n      <td>7</td>\n      <td>False</td>\n      <td>[&lt;https://www.coursera.org/learn/reinforcement...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Кто-нибудь знает готовые реализации для обнару...</td>\n      <td>None</td>\n      <td>66</td>\n      <td>False</td>\n      <td>[Что можно почитать на тему отслеживание анома...</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('data/qq_sim.parquet', compression='brotli', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С использованием SentenceBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from modules.evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/qa_clean.parquet')\n",
    "graph = pd.read_parquet('data/qa_sim.parquet').loc[:, ['q_id', 'ans_ids']]\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question'] = df['question'].str.lower()\n",
    "df['answer'] = df['answer'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df['question'].unique()\n",
    "answers = df['answer'].to_numpy()\n",
    "similarity = []\n",
    "for st in graph['ans_ids'].to_numpy():\n",
    "    el = eval(st)\n",
    "    if isinstance(el, int):\n",
    "        similarity.append([el])\n",
    "    else:\n",
    "        similarity.append(list(el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 100%|██████████| 164/164 [10:39<00:00,  3.90s/it]\n",
      "Calculating embeddings: 100%|██████████| 771/771 [18:40<00:00,  1.45s/it]\n",
      "Searching: 100%|██████████| 21018/21018 [11:28<00:00, 30.52it/s]\n"
     ]
    }
   ],
   "source": [
    "map10 = evaluate(model, questions, answers, similarity, model_type='sbert', batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0494763472063598\n"
     ]
    }
   ],
   "source": [
    "print(map10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ODS-QA",
   "language": "python",
   "name": "ods-qa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}