{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'modules'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-91ec52d9b157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_text\u001b[0m \u001b[0;31m# Not used directly but needed to import TF ops.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalculate_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'modules'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text # Not used directly but needed to import TF ops.\n",
    "\n",
    "from modules.evaluation import calculate_embeddings, Index\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/qq_sim.parquet')\n",
    "questions = df['question'].unique()\n",
    "model = hub.KerasLayer(\"models/USEm_large3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df2['question'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Calculating embeddings: 100%|██████████| 328/328 [26:52<00:00,  4.92s/it]\n"
    }
   ],
   "source": [
    "quest_vectors = {}\n",
    "embs = calculate_embeddings(model, questions, dims=512, model_type='use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "21018it [00:00, 491645.00it/s]\n"
    }
   ],
   "source": [
    "for i, question in tqdm(enumerate(questions)):\n",
    "    quest_vectors.update({question: embs[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_parquet('data/qa_clean.parquet')\n",
    "answers = df2['answer'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Calculating embeddings: 100%|██████████| 771/771 [33:55<00:00,  2.64s/it]\n49394it [00:00, 1078578.99it/s]\n"
    }
   ],
   "source": [
    "ans_vectors = {}\n",
    "embs = calculate_embeddings(model, answers, dims=512, model_type='use')\n",
    "for i, answer in tqdm(enumerate(answers)):\n",
    "    ans_vectors.update({answer: embs[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/not_load/questions_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(quest_vectors, f)\n",
    "with open('data/not_load/answers_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(ans_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Calculating embeddings: 100%|██████████| 80/80 [06:13<00:00,  4.66s/it]\n"
    }
   ],
   "source": [
    "search_index = Index(model, questions, 512, model_type='use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'а кроме wiki, какие существуют хорошие датасеты для multilabel text classification?'"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "sample = df2[df2['channel'] == 'datasets'].sample()\n",
    "sample['question'].to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates, _ = search_index.search(quest_vectors[sample['question'].to_numpy()[0]].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Привет! А кто-нибудь знает датасеты для классификации текстов на русском языке? Хотелось бы что-то типа 20newsgroups, но только для великого и могучего. П.С. знаю, что можно намайнить, но лень)',\n 'всем привет!\\nкто-нибудь знает какие-нибудь статьи/ссылки по сравнению (по любой метрике) различных моделей для классификации текста? идеально было бы для IMDB датасета',\n 'Привет. Есть ли где-нибудь датасет размеченных текстов на русском языке по темам?',\n 'Господа а какие есть тулзы упрощающие разметку текстовых датасетов?',\n 'Привет, пацаны. Мне нужен очень большой датасет текстов на русском языке, типа всей русскоязычной википедии. Может быть знаете, кто-то уже выкачивал такое и где можно это найти?',\n 'Всем привет. А может у кого-то есть классификатор товаров по категориям на русском или может какой-нибудь датасет подходящий знаете?',\n 'кто-нибудь знает какие сейчас существуют интересные SOTA (но необязательно) методы для content labeling? То есть присваивать человечески читаемые категории текстовым документам.',\n 'Всем привет!\\nМожете посоветовать какие-нибудь годные дата-сеты для Named entity recognition на русском?\\nНу или годные библиотеки/статьи.',\n 'гайз, а какие нынче best practices по pseudolabeling для классификации? как лучше всего из predictions в “true” labels отбирать? или какие еще умные методы по self-supervised learning?\\n\\nPS. no kaggle, просто хочу под autolabel побольше фичей собрать',\n 'Подскажите пожалуйста, есть где список доступных датасетов для nlp?\\nСобираюсь писать pet-project в тематике nlp, отталкиваться думаю от темы/количества/качества датасета']"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['arxiv, еще на гитхабе лейблы появились, может быть можно где-то дамп найти',\n       'я в <#C0KL2AXD3|datasets> выкладывал 1.5m статей с medium, там есть теги.',\n       'около 2000 вроде.',\n       'stackexchange по разным темам вопросы с тегами'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "query_answers = df2[df2['question'] == sample['question'].to_numpy()[0]]['answer'].to_numpy(); query_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[array(['тут <https://tatianashavrina.github.io/taiga_site/downloads> есть новости',\n        'Есть вот такой для чатботов <https://toloka.yandex.ru/datasets/>',\n        '<https://github.com/buriy/russian-nlp-datasets/releases/tag/r4>'],\n       dtype=object),\n array(['<https://paperswithcode.com/sota/sentiment-analysis-on-imdb>\\n\\n<https://paperswithcode.com/sota>',\n        '<https://ahmedbesbes.com/overview-and-benchmark-of-traditional-and-deep-learning-models-in-text-classification.html>',\n        '<http://nlpprogress.com/english/sentiment_analysis.html>'],\n       dtype=object),\n array(['polo: Как вариант, можешь распарсить новостные источники. Вот, например, я парсил Ленту <https://github.com/yutkin/lenta.ru-news-dataset>.'],\n       dtype=object),\n array(['<http://brat.nlplab.org/>'], dtype=object),\n array(['Ссылку не доставлю, под рукой нет. Но гуглить по типу wiki dump',\n        'Википедия маленькая, но если нужна -- погугли по этому слаку. Дамп бери cirrussearch, иначе шаблоны будут не раскрыты. А лучше вообще kiwix. Также есть\\nFlibusta , librusec, taiga, araneum.',\n        '<@U562KSN69> статьи -- научная деятельность, значит, это законное использование корпуса. И даже если бы в корпусе было бы явно написано \"не для научных целей\", закон защищает учёных, позволяя им исследовать разные вещи.'],\n       dtype=object),\n array(['там только заголовки были, да'], dtype=object),\n array([\"Википедия может подойти. Или вроде бы дамп arxiv'а где-то был\"],\n       dtype=object),\n array(['Датасет <https://github.com/dialogue-evaluation/factRuEval-2016/> . Библиотека <https://github.com/bureaucratic-labs/natasha>'],\n       dtype=object),\n array(['на machines can see был доклад, где парни рассказывали, что лучше использовать в качестве лейбла для новой сетки (у них была teacher-student история) не one-hot, а промежуточную активацию, а ещё лучше — softmax выхода (а не hardmax).',\n        'Кажется, я тебе уже скидывал эту статью, или нет?\\n<https://arxiv.org/abs/1706.00909>'],\n       dtype=object),\n array(['<@U7KDVG6LS> <https://tatianashavrina.github.io/taiga_site/>'],\n       dtype=object)]"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "candidates_answers = []\n",
    "for cand in candidates:\n",
    "    candidates_answers.append(df2[df2['question'] == cand]['answer'].to_numpy())\n",
    "\n",
    "candidates_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "table = []\n",
    "for ans in query_answers:\n",
    "    a = []\n",
    "    for cands in candidates_answers:\n",
    "        c = []\n",
    "        for cand in cands:\n",
    "            c.append(cosine(ans_vectors[ans], ans_vectors[cand]))\n",
    "        a.append(c)\n",
    "    table.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[[0.8172813802957535, 0.9083745554089546, 0.8315234333276749],\n  [0.9691755156964064, 1.007233098614961, 1.0146066658198833],\n  [0.9150481224060059],\n  [0.9349732547998428],\n  [0.8696997463703156, 0.7376111447811127, 0.9362394958734512],\n  [0.832336887717247],\n  [0.5044894218444824],\n  [0.9202183857560158],\n  [0.8712908327579498, 0.8729972988367081],\n  [0.9000867381691933]],\n [[0.7655701637268066, 0.7902668118476868, 0.7274530529975891],\n  [0.7958397567272186, 0.8685403913259506, 0.8821618929505348],\n  [0.6144543588161469],\n  [0.8915234208106995],\n  [0.6944743990898132, 0.6880724728107452, 0.8641466796398163],\n  [0.7651455849409103],\n  [0.7577382773160934],\n  [0.7824581116437912],\n  [0.7887020111083984, 0.6699787676334381],\n  [0.8169232308864594]],\n [[0.9631971195340157, 0.9263541921973228, 0.9901438821107149],\n  [0.970547741279006, 0.9943454670719802, 0.9420468583703041],\n  [1.0014581942232326],\n  [0.8481171280145645],\n  [0.8794928044080734, 0.9135652184486389, 0.9912729542702436],\n  [0.8854565322399139],\n  [0.8091249167919159],\n  [0.999936311491183],\n  [0.9922178760170937, 1.023028401657939],\n  [1.002398518146947]],\n [[0.9030425325036049, 0.8667605817317963, 0.7831816673278809],\n  [0.8969462886452675, 0.8917843699455261, 0.9720977079123259],\n  [0.9324885681271553],\n  [0.971496069803834],\n  [0.8268480896949768, 0.8770639151334763, 0.9191262871026993],\n  [0.7814309895038605],\n  [0.8997813984751701],\n  [0.8806463330984116],\n  [0.9018170535564423, 0.9886970249935985],\n  [0.8796521201729774]]]\n"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "От ответов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Calculating embeddings: 100%|██████████| 771/771 [46:03<00:00,  3.58s/it]\n"
    }
   ],
   "source": [
    "search_idx = Index(model, answers, 512, model_type='use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _try_ans():\n",
    "    sample = df2[df2['channel'] == 'datasets'].sample()\n",
    "    print(f\"Random answer: {sample['answer'].to_numpy()[0]}\")\n",
    "    candidates, _ = search_idx.search(ans_vectors[sample['answer'].to_numpy()[0]].reshape(1, -1))\n",
    "\n",
    "    candidates_questions = []\n",
    "    for cand in candidates:\n",
    "        candidates_questions.append(df2[df2['answer'] == cand]['question'].to_numpy())\n",
    "\n",
    "    table = []\n",
    "    q = sample['question'].to_numpy()[0]\n",
    "    for cands in candidates_questions:\n",
    "        for cand in cands:\n",
    "            try:\n",
    "                table.append((cand, cosine(quest_vectors[q], quest_vectors[cand])))\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "    print(f'Question for that answer: {q}\\nCandidates:\\n')\n",
    "    pprint(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'microsoft malware classification challenge'"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "sample = df2[df2['channel'] == 'datasets'].sample()\n",
    "sample['answer'].to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates, _ = search_idx.search(ans_vectors[sample['answer'].to_numpy()[0]].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_questions = []\n",
    "for cand in candidates:\n",
    "    candidates_questions.append(df2[df2['answer'] == cand]['question'].to_numpy())\n",
    "\n",
    "#candidates_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Добрый вечер! Подскажите, пожалуйста: где можно достать датасет по malware? Данные статического (тип файла, результат выполнения strings, импорты dll и т.д.) или динамического (какая команда в какой момент времени выполнялась, создаваемые процессы и т.д.) анализа какой-нибудь выборки вирусов или другого вредоносного по. Цель - анализ данных при помощи визуализации. Заранее спасибо :slightly_smiling_face:\n[('А можете посоветовать датасет для определения парафраз? датасет от quora '\n  'уже видел, интересует что-то другое',\n  0.6053649485111237)]\n"
    }
   ],
   "source": [
    "table = []\n",
    "q = sample['question'].to_numpy()[0]\n",
    "for cands in candidates_questions:\n",
    "    for cand in cands:\n",
    "        try:\n",
    "            table.append((cand, cosine(quest_vectors[q], quest_vectors[cand])))\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "print(q)\n",
    "pprint(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Random answer: Там больше 800 тысяч словоформ, и, конечно же, это делалось скриптом :slightly_smiling_face: А в качестве алгоритма g2p использовался <https://github.com/nsu-ai/russian_g2p>\nВручную сделанные транскрипции тоже есть, но их совсем немного, несколько сотен, и они сделаны для аббревиатур типа \"мгу\" и подобных\nQuestion for that answer: Всем привет! Нет ли у кого нибудь датасета grapheme2phoneme на русском языке?\nCandidates:\n\n[('*TLDR: Какие NLP модели подходят мобильным платформам?*\\n'\n  '\\n'\n  'Взращиваю сад моделей TF.js и вижу, что представлено не так много сетей, '\n  'работающих с языком: есть Universal Sentence Encoder '\n  '(<https://github.com/tensorflow/tfjs-models/tree/master/universal-sentence-encoder>) '\n  'с вокабуляром 8к и результирующими эмбеддингами в 512, есть классификатор '\n  'токсика, есть распознователь голосовых команд. Была идея портировать HNAtt '\n  '(<https://github.com/minqi/hnatt>), но она базируется на Glove, да и '\n  'функционал пересекается с токсиком.\\n'\n  '\\n'\n  'На ACL 2019 встречается несколько работ, посвященных on-device networks, '\n  'например:\\n'\n  '\\n'\n  '- \"On-device Structured and Context Partitioned Projection Networks\" от '\n  'давно работающего в этой области <http://www.sravi.org/> в коавторах, '\n  'статьи пока не видел, но на сайте можно посмотреть работы в духе, о '\n  'Self-Governing Neural Networks и ProjectionNets\\n'\n  '- \"Lightweight and Efficient Neural Natural Language Processing with '\n  'Quaternion Networks\", ссылка: <https://arxiv.org/pdf/1906.04393.pdf>, '\n  'выложили имплементацию 5 часов назад: '\n  '<https://github.com/vanzytay/QuaternionTransformers>\\n'\n  '\\n'\n  'Тема горячая, было бы здорово найти готовые решения на TensorFlow/Keras, но '\n  'и PyTorch хорошо. Есть SmartReply от того же S. Ravi, но он на TFLite.\\n'\n  '\\n'\n  '<https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/models/smartreply>\\n'\n  '\\n'\n  'Было бы круто его перевести на TensorFlow, но я этим пока не занимался и не '\n  'знаю как подойти.\\n'\n  '\\n'\n  'Была идея поработать с эмбеддингами помимо USE (спасибо, <@U0H7VBQQ1>), но '\n  'тоже пока в недоумении, как эффективно это сделать.\\n'\n  '\\n'\n  'Есть ли мобильно-ориентированные NLP архитектуры, которые приходят на ум?',\n  0.8331612944602966),\n ('Всем привет! Нет ли у кого нибудь датасета grapheme2phoneme на русском '\n  'языке?',\n  0.0),\n ('Какие есть способы геренации похожего семантически текста по существующему. '\n  'Например я хочу кинуть в модель 2 предложения и ожидаю на выход получить '\n  'похожий по смыслу текст, но с другим словарным запасом оборотами. Видел в '\n  'статейке, что берт может тут части фраз предсказывать, кто-то может '\n  'пробовал такое?\\n'\n  '<https://m.habr.com/ru/post/436878/>\\n'\n  'Или может какой-нибудь автокодировщик обучить',\n  0.7879116386175156),\n ('У меня есть 150к английских слов, нужно для каждого слова три синонима. '\n  'Первая идея – взять из w2v top 3 для каждого слова. Но работает очень '\n  'долго, 4 слова в секунду, параллелить не вариант, так как нужно передавать '\n  'w2v в каждый процесс, а он 4гб. Пробовал wordnet, но чет вообще не очень. '\n  'Что посоветуете?',\n  0.8486319482326508),\n ('Могу ли я с помощью doc2vec делать представления для новых предложений, или '\n  'он только ищет вектора для предложений из обучения?',\n  0.8312701135873795),\n ('существует ли какой-нибудь word2vec с дообучением? и в нем, и в glove если '\n  'получаешь векторное представление, модель вроде замораживается и дообучить '\n  'нельзя, а хочется не совсем сильно меняя пространство, чуть-чуть менять '\n  'вектора по новым данным и вводить новые слова',\n  0.741300493478775),\n ('Всем привет! Я хочу научиться переводить фамилии в вектора. LastName2vec... '\n  'Кажется довольно логичным, что у нас есть какая-нибудь char rnn + dense '\n  'слой. Предсказываем следующую букву по предыдущим. Эмбедингом можно считать '\n  'веса с dense слоя, когда предсказываем пробел после слова. Кажется, что я '\n  'понимаю что-то неправильно. Ибо непонятно как такое обучать(можно склеить '\n  'все слова через пробелы в один текст(случайно пошафля)). Будет моя идея '\n  'работать или нет?',\n  0.782622441649437),\n ('Есть обученные lite-версии w2v для английского? Гугловский, конечно, хорош, '\n  'но из-за своих размеров не всегда могу использовать.',\n  0.663041889667511),\n ('Подскажите, почему очень медленно идёт выполнение вот этой функции? Вроде '\n  'ничего сверхординарного, обычные операции, но даже для сотни текстов (750 '\n  'символов в среднем) начинаются тормоза.',\n  0.9260081127285957),\n ('Подскажите, пжста, как достать окончание из слова?', 0.8712818771600723)]\n"
    }
   ],
   "source": [
    "_try_ans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['analytiсs', 'audio_and_speech', 'bayesian', 'big_data', 'bioinformatics', 'blockchain', 'cloud', 'datasets',\n",
    "            'deep_learning', 'devops', 'gan', 'gis', 'lang_cpp', 'lang_go', 'lang_javascript', 'lang_julia', 'lang_python'\n",
    "            'lang_r', 'lang_scala', 'math', 'nlp', 'recommender_systems', 'reinforcement_learning', 'risk_modelling', \n",
    "            'satellite_imaging', 'trading', 'visualization']\n",
    "\n",
    "df = df2[df2['channel'].isin(channels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(columns=['question', 'similiar_questions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['question'] = df['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "''"
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "str(similiar_questions).strip('[]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 10333/10333 [10:01<00:00, 17.17it/s]\n"
    }
   ],
   "source": [
    "list_for_clusterization = []\n",
    "append_flag = False\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    question = row['question']\n",
    "    similiar_questions = []\n",
    "    answer = row['answer']\n",
    "    candidates, _ = search_idx.search(ans_vectors[answer].reshape(1, -1))\n",
    "\n",
    "    candidates_questions = []\n",
    "    for cand in candidates:\n",
    "        candidates_questions.append(df[df['answer'] == cand]['question'].to_numpy())\n",
    "\n",
    "    for cand_array in candidates_questions:\n",
    "        for cand in cand_array:\n",
    "            try:\n",
    "                distance = cosine(quest_vectors[question], quest_vectors[cand])\n",
    "                if all((distance <= 0.5, distance > 0)):\n",
    "                    similiar_questions.append(cand)\n",
    "                    list_for_clusterization.append(cand)\n",
    "                    append_flag = True\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "    if append_flag:\n",
    "        list_for_clusterization.append(question)\n",
    "        append_flag = False\n",
    "    \n",
    "    similiar_questions = str(similiar_questions).strip('[]')\n",
    "    if similiar_questions == '':\n",
    "        similiar_questions = np.nan\n",
    "    df_new.loc[i, 'similiar_questions'] = similiar_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 10333 entries, 0 to 48559\nData columns (total 2 columns):\n #   Column              Non-Null Count  Dtype \n---  ------              --------------  ----- \n 0   question            10333 non-null  object\n 1   similiar_questions  680 non-null    object\ndtypes: object(2)\nmemory usage: 562.2+ KB\n"
    }
   ],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                question  \\\n120    Подскажите, что обычно используют для разметки...   \n124    Вопрос может показаться туповатым, но я раньше...   \n285    Кто сталкивался c OCR? Есть ли что-то готовое ...   \n296    Я понимаю, что уже всех заколебал, но пока чат...   \n306    Какая ваша любимая библиотека для pytorch, обл...   \n...                                                  ...   \n46873  Подскажите, пожалуйста, чем рисуют архитектуры...   \n46878  доброго дня. У меня есть некий датасет с двумя...   \n46885  Если бы у вас внезапно проступило желание забо...   \n46905  Хей. Есть функция: r = sin(a)*cos(a*3/2), где ...   \n46910  Всем привет, подскажите, пожалуйста, с какой н...   \n\n                                      similiar_questions  \n120    'Ребят, какой посоветуете удобный инструмент д...  \n124    'Здравствуйте. Есть ли в Python Matlab-like ви...  \n285    'чат, а есть что-то более актуальное про OCR с...  \n296    'Ребят, задача бинарной сегментации :resnet34:...  \n306    \"Вопрос к любителям :pytorch1-0: Как вы обучае...  \n...                                                  ...  \n46873  'Народ, а кто какие тулы использует для рисова...  \n46878  'Здравствуйте. Есть ли в Python Matlab-like ви...  \n46885  'Друзья, привет! Есть ли какая то питоновская ...  \n46905  'Кто-то знает, как сделать чтобы графики не на...  \n46910  'коллеги, начал изучать matplotlib, в обучающе...  \n\n[546 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>similiar_questions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>120</th>\n      <td>Подскажите, что обычно используют для разметки...</td>\n      <td>'Ребят, какой посоветуете удобный инструмент д...</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>Вопрос может показаться туповатым, но я раньше...</td>\n      <td>'Здравствуйте. Есть ли в Python Matlab-like ви...</td>\n    </tr>\n    <tr>\n      <th>285</th>\n      <td>Кто сталкивался c OCR? Есть ли что-то готовое ...</td>\n      <td>'чат, а есть что-то более актуальное про OCR с...</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>Я понимаю, что уже всех заколебал, но пока чат...</td>\n      <td>'Ребят, задача бинарной сегментации :resnet34:...</td>\n    </tr>\n    <tr>\n      <th>306</th>\n      <td>Какая ваша любимая библиотека для pytorch, обл...</td>\n      <td>\"Вопрос к любителям :pytorch1-0: Как вы обучае...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>46873</th>\n      <td>Подскажите, пожалуйста, чем рисуют архитектуры...</td>\n      <td>'Народ, а кто какие тулы использует для рисова...</td>\n    </tr>\n    <tr>\n      <th>46878</th>\n      <td>доброго дня. У меня есть некий датасет с двумя...</td>\n      <td>'Здравствуйте. Есть ли в Python Matlab-like ви...</td>\n    </tr>\n    <tr>\n      <th>46885</th>\n      <td>Если бы у вас внезапно проступило желание забо...</td>\n      <td>'Друзья, привет! Есть ли какая то питоновская ...</td>\n    </tr>\n    <tr>\n      <th>46905</th>\n      <td>Хей. Есть функция: r = sin(a)*cos(a*3/2), где ...</td>\n      <td>'Кто-то знает, как сделать чтобы графики не на...</td>\n    </tr>\n    <tr>\n      <th>46910</th>\n      <td>Всем привет, подскажите, пожалуйста, с какой н...</td>\n      <td>'коллеги, начал изучать matplotlib, в обучающе...</td>\n    </tr>\n  </tbody>\n</table>\n<p>546 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "df_new[df_new['similiar_questions'].notna()].drop_duplicates('question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                  channel                                           question  \\\n0                 lang_go  Народ, кто знает, есть ли в GO библиотека для ...   \n1                 lang_go  Всем привет, нуждаюсь в помощи по составлению ...   \n2                 lang_go  Всем привет, нуждаюсь в помощи по составлению ...   \n3                 lang_go  Всем привет, нуждаюсь в помощи по составлению ...   \n4                 lang_go  Всем привет, нуждаюсь в помощи по составлению ...   \n...                   ...                                                ...   \n49389  proj_kaggle_2sigma  Как то можно писать в лог в процессе commit, ч...   \n49390  proj_kaggle_2sigma  Как то можно писать в лог в процессе commit, ч...   \n49391  proj_kaggle_2sigma  Ребят, а подскажите, я некоторое время назад с...   \n49392  proj_kaggle_2sigma  Ребят, а подскажите, я некоторое время назад с...   \n49393  proj_kaggle_2sigma  Трейдингом раньше не занимался. Подскажите, мо...   \n\n                                                  answer  \\\n0      Шатать таблички в го это, как летать на дачу н...   \n1      Зачем эта простыня текста. Ее традиционно никт...   \n2      > в проект Data Science\\nвыглядит как bullshit...   \n3                     <@U64GCA997> сильно лучше :notbad:   \n4      Что такое бустануть? Что за нужно уметь в них?...   \n...                                                  ...   \n49389  можно `logging` юзать. тогда можно одно и тоже...   \n49390  например так:\\n```# Set up a logger to dump me...   \n49391  насколько я понимаю, после того как закончится...   \n49392  1. Решения нет - это вообще бесспорно. 4 - наи...   \n49393  Не думаю что в лоб можно так утверждать, хотя ...   \n\n                                               reactions  \n0              [{'name': 'heavy_plus_sign', 'count': 1}]  \n1      [{'name': 'tnx', 'count': 1}, {'name': 'heavy_...  \n2                           [{'name': '+1', 'count': 1}]  \n3                          [{'name': 'tnx', 'count': 1}]  \n4      [{'name': 'heavy_plus_sign', 'count': 1}, {'na...  \n...                                                  ...  \n49389                      [{'name': 'tnx', 'count': 1}]  \n49390                       [{'name': '+1', 'count': 1}]  \n49391          [{'name': 'heavy_plus_sign', 'count': 2}]  \n49392  [{'name': '+1', 'count': 1}, {'name': 'heavy_p...  \n49393                      [{'name': 'tnx', 'count': 1}]  \n\n[49394 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>channel</th>\n      <th>question</th>\n      <th>answer</th>\n      <th>reactions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>lang_go</td>\n      <td>Народ, кто знает, есть ли в GO библиотека для ...</td>\n      <td>Шатать таблички в го это, как летать на дачу н...</td>\n      <td>[{'name': 'heavy_plus_sign', 'count': 1}]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>lang_go</td>\n      <td>Всем привет, нуждаюсь в помощи по составлению ...</td>\n      <td>Зачем эта простыня текста. Ее традиционно никт...</td>\n      <td>[{'name': 'tnx', 'count': 1}, {'name': 'heavy_...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>lang_go</td>\n      <td>Всем привет, нуждаюсь в помощи по составлению ...</td>\n      <td>&gt; в проект Data Science\\nвыглядит как bullshit...</td>\n      <td>[{'name': '+1', 'count': 1}]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>lang_go</td>\n      <td>Всем привет, нуждаюсь в помощи по составлению ...</td>\n      <td>&lt;@U64GCA997&gt; сильно лучше :notbad:</td>\n      <td>[{'name': 'tnx', 'count': 1}]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>lang_go</td>\n      <td>Всем привет, нуждаюсь в помощи по составлению ...</td>\n      <td>Что такое бустануть? Что за нужно уметь в них?...</td>\n      <td>[{'name': 'heavy_plus_sign', 'count': 1}, {'na...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49389</th>\n      <td>proj_kaggle_2sigma</td>\n      <td>Как то можно писать в лог в процессе commit, ч...</td>\n      <td>можно `logging` юзать. тогда можно одно и тоже...</td>\n      <td>[{'name': 'tnx', 'count': 1}]</td>\n    </tr>\n    <tr>\n      <th>49390</th>\n      <td>proj_kaggle_2sigma</td>\n      <td>Как то можно писать в лог в процессе commit, ч...</td>\n      <td>например так:\\n```# Set up a logger to dump me...</td>\n      <td>[{'name': '+1', 'count': 1}]</td>\n    </tr>\n    <tr>\n      <th>49391</th>\n      <td>proj_kaggle_2sigma</td>\n      <td>Ребят, а подскажите, я некоторое время назад с...</td>\n      <td>насколько я понимаю, после того как закончится...</td>\n      <td>[{'name': 'heavy_plus_sign', 'count': 2}]</td>\n    </tr>\n    <tr>\n      <th>49392</th>\n      <td>proj_kaggle_2sigma</td>\n      <td>Ребят, а подскажите, я некоторое время назад с...</td>\n      <td>1. Решения нет - это вообще бесспорно. 4 - наи...</td>\n      <td>[{'name': '+1', 'count': 1}, {'name': 'heavy_p...</td>\n    </tr>\n    <tr>\n      <th>49393</th>\n      <td>proj_kaggle_2sigma</td>\n      <td>Трейдингом раньше не занимался. Подскажите, мо...</td>\n      <td>Не думаю что в лоб можно так утверждать, хотя ...</td>\n      <td>[{'name': 'tnx', 'count': 1}]</td>\n    </tr>\n  </tbody>\n</table>\n<p>49394 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 665/665 [00:03<00:00, 173.22it/s]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                               question        channel\n0     Ребят, какой посоветуете удобный инструмент дл...  deep_learning\n1     Подскажите, что обычно используют для разметки...            gis\n2     Здравствуйте. Есть ли в Python Matlab-like виз...  visualization\n3     Вопрос может показаться туповатым, но я раньше...            gis\n6     чат, а есть что-то более актуальное про OCR се...  deep_learning\n...                                                 ...            ...\n1483  Друзья, привет! Подскажите пожалуйста каким об...  visualization\n1489  Друзья, привет! сейчас будет нубский вопрос, a...  visualization\n1513  Друзья, привет! Есть ли какая то питоновская б...  visualization\n1514  Если бы у вас внезапно проступило желание забо...  visualization\n1518  Всем привет, подскажите, пожалуйста, с какой н...  visualization\n\n[665 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>channel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ребят, какой посоветуете удобный инструмент дл...</td>\n      <td>deep_learning</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Подскажите, что обычно используют для разметки...</td>\n      <td>gis</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Здравствуйте. Есть ли в Python Matlab-like виз...</td>\n      <td>visualization</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Вопрос может показаться туповатым, но я раньше...</td>\n      <td>gis</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>чат, а есть что-то более актуальное про OCR се...</td>\n      <td>deep_learning</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1483</th>\n      <td>Друзья, привет! Подскажите пожалуйста каким об...</td>\n      <td>visualization</td>\n    </tr>\n    <tr>\n      <th>1489</th>\n      <td>Друзья, привет! сейчас будет нубский вопрос, a...</td>\n      <td>visualization</td>\n    </tr>\n    <tr>\n      <th>1513</th>\n      <td>Друзья, привет! Есть ли какая то питоновская б...</td>\n      <td>visualization</td>\n    </tr>\n    <tr>\n      <th>1514</th>\n      <td>Если бы у вас внезапно проступило желание забо...</td>\n      <td>visualization</td>\n    </tr>\n    <tr>\n      <th>1518</th>\n      <td>Всем привет, подскажите, пожалуйста, с какой н...</td>\n      <td>visualization</td>\n    </tr>\n  </tbody>\n</table>\n<p>665 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "cluster_df = pd.DataFrame(columns=['question', 'channel'])\n",
    "cluster_df['question'] = list_for_clusterization\n",
    "cluster_df.drop_duplicates('question', inplace=True)\n",
    "for i, row in tqdm(cluster_df.iterrows(), total=len(cluster_df)):\n",
    "    row['channel'] = df2[df2['question'] == row['question']]['channel'].to_numpy()[0]\n",
    "\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df.to_parquet('data/not_load/sim_clusters.parquet', compression='brotli', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_parquet('data/not_load/qq_sim_from_use.parquet', compression='brotli', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../data/not_load/qq_sim_from_use.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                question  \\\n62     Подскажите, что обычно используют для разметки...   \n66     Вопрос может показаться туповатым, но я раньше...   \n67     Вопрос может показаться туповатым, но я раньше...   \n108    Кто сталкивался c OCR? Есть ли что-то готовое ...   \n119    Я понимаю, что уже всех заколебал, но пока чат...   \n...                                                  ...   \n10163  Подскажите, пожалуйста, чем рисуют архитектуры...   \n10166  доброго дня. У меня есть некий датасет с двумя...   \n10173  Если бы у вас внезапно проступило желание забо...   \n10193  Хей. Есть функция: r = sin(a)*cos(a*3/2), где ...   \n10198  Всем привет, подскажите, пожалуйста, с какой н...   \n\n                                      similiar_questions  \n62     'Ребят, какой посоветуете удобный инструмент д...  \n66     'Здравствуйте. Есть ли в Python Matlab-like ви...  \n67     'Здравствуйте. Есть ли в Python Matlab-like ви...  \n108    'чат, а есть что-то более актуальное про OCR с...  \n119    'Ребят, задача бинарной сегментации :resnet34:...  \n...                                                  ...  \n10163  'Привет, часто встречаю диаграммы архитектур н...  \n10166  'Здравствуйте. Есть ли в Python Matlab-like ви...  \n10173  'Друзья, привет! Есть ли какая то питоновская ...  \n10193  'Кто-то знает, как сделать чтобы графики не на...  \n10198  'коллеги, начал изучать matplotlib, в обучающе...  \n\n[680 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>similiar_questions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>62</th>\n      <td>Подскажите, что обычно используют для разметки...</td>\n      <td>'Ребят, какой посоветуете удобный инструмент д...</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>Вопрос может показаться туповатым, но я раньше...</td>\n      <td>'Здравствуйте. Есть ли в Python Matlab-like ви...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>Вопрос может показаться туповатым, но я раньше...</td>\n      <td>'Здравствуйте. Есть ли в Python Matlab-like ви...</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>Кто сталкивался c OCR? Есть ли что-то готовое ...</td>\n      <td>'чат, а есть что-то более актуальное про OCR с...</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>Я понимаю, что уже всех заколебал, но пока чат...</td>\n      <td>'Ребят, задача бинарной сегментации :resnet34:...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10163</th>\n      <td>Подскажите, пожалуйста, чем рисуют архитектуры...</td>\n      <td>'Привет, часто встречаю диаграммы архитектур н...</td>\n    </tr>\n    <tr>\n      <th>10166</th>\n      <td>доброго дня. У меня есть некий датасет с двумя...</td>\n      <td>'Здравствуйте. Есть ли в Python Matlab-like ви...</td>\n    </tr>\n    <tr>\n      <th>10173</th>\n      <td>Если бы у вас внезапно проступило желание забо...</td>\n      <td>'Друзья, привет! Есть ли какая то питоновская ...</td>\n    </tr>\n    <tr>\n      <th>10193</th>\n      <td>Хей. Есть функция: r = sin(a)*cos(a*3/2), где ...</td>\n      <td>'Кто-то знает, как сделать чтобы графики не на...</td>\n    </tr>\n    <tr>\n      <th>10198</th>\n      <td>Всем привет, подскажите, пожалуйста, с какой н...</td>\n      <td>'коллеги, начал изучать matplotlib, в обучающе...</td>\n    </tr>\n  </tbody>\n</table>\n<p>680 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df.dropna(inplace=True); df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Всем привет. Хочу перекатиться с :keras: на :pytorch1-0:. Есть какие нибудь гайды (на пример как создавать `dataloader`и подобное), чтоб быстро вкатиться. Или сразу использовать :catalyst:?'"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "df.loc[13, 'question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"':catalyst: :keras: А какие аналоги Catalyst есть для Keras?\\\\n\\\\nНужна штука которая позволяет красиво и удобно настроить кучу моделей и гиперпараметров, отправить это дело учиться и собирать метрики, чтобы потом любоваться на графики и выбирать самое сочное'\""
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "df.loc[13, 'similiar_questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "546"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "len(df['question'].unique())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "ods-qa",
   "display_name": "ODS-QA"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}